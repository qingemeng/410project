{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nmslib\n",
    "\n",
    "from lang_model_utils import load_lm_vocab, Query2Emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lang_model_utils import load_lm_vocab, Query2Emb\n",
    "# from general_utils import create_nmslib_search_index\n",
    "\n",
    "input_path = Path('./data/stackoverflow/processed_data/')\n",
    "# code2emb_path = Path('./data/code2emb/')\n",
    "output_path = Path('./data/stackoverflow/search')\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank results with similarity, votes, and comments semtiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_df = pd.read_csv(input_path/'test.content_token', header=None, names=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Read in votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of votes\n",
    "vote_df = pd.read_csv(input_path/'test.vote', header=None, names=['vote'])\n",
    "assert body_df.shape[0] == vote_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of comments\n",
    "comment_df = pd.read_csv(input_path/'test.comment', header=None, names=['comment'])\n",
    "assert body_df.shape[0] == comment_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of urls\n",
    "url_df = pd.read_csv(input_path/'test.url', header=None, names=['url'])\n",
    "assert body_df.shape[0] == url_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>comment</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stackoverflow.com/a/18622422</td>\n",
       "      <td>first , create a list containing one hundred d...</td>\n",
       "      <td>Hi Kevin, I tried the latter code and it worke...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://stackoverflow.com/a/5185748</td>\n",
       "      <td>i 've had a similar problem and i 've ended up...</td>\n",
       "      <td>IMO Fabio's solution is quite to the point :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://stackoverflow.com/a/59841</td>\n",
       "      <td>two options that do n't require copying the wh...</td>\n",
       "      <td>`next(iter(your_list or []), None)` to handle ...</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://stackoverflow.com/a/2659296</td>\n",
       "      <td>i do n't think you can do this in one database...</td>\n",
       "      <td>Thanks. Note that in the example you gave, the...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stackoverflow.com/a/26097790</td>\n",
       "      <td>for python 3 :</td>\n",
       "      <td>@MartijnPieters Do you know what version intro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url  \\\n",
       "0  https://stackoverflow.com/a/18622422   \n",
       "1   https://stackoverflow.com/a/5185748   \n",
       "2     https://stackoverflow.com/a/59841   \n",
       "3   https://stackoverflow.com/a/2659296   \n",
       "4  https://stackoverflow.com/a/26097790   \n",
       "\n",
       "                                             content  \\\n",
       "0  first , create a list containing one hundred d...   \n",
       "1  i 've had a similar problem and i 've ended up...   \n",
       "2  two options that do n't require copying the wh...   \n",
       "3  i do n't think you can do this in one database...   \n",
       "4                                     for python 3 :   \n",
       "\n",
       "                                             comment  vote  \n",
       "0  Hi Kevin, I tried the latter code and it worke...     4  \n",
       "1      IMO Fabio's solution is quite to the point :)     1  \n",
       "2  `next(iter(your_list or []), None)` to handle ...   371  \n",
       "3  Thanks. Note that in the example you gave, the...     7  \n",
       "4  @MartijnPieters Do you know what version intro...     4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect these two together into a dataframe\n",
    "ref_df = pd.concat([url_df, body_df, comment_df, vote_df], axis = 1).reset_index(drop=True)\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw contents\n",
    "with open(input_path/'train.content_token', 'r') as f:\n",
    "    trn_raw = f.readlines()\n",
    "\n",
    "with open(input_path/'valid.content_token', 'r') as f:\n",
    "    val_raw = f.readlines()\n",
    "    \n",
    "with open(input_path/'test.content_token', 'r') as f:\n",
    "    test_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loaded vocab of size 27,877\n"
     ]
    }
   ],
   "source": [
    "# load vocab \n",
    "vocab = load_lm_vocab('./data/stackoverflow/lang_model/vocab.cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load language model\n",
    "lang_model = torch.load('./data/stackoverflow/lang_model/lang_model_cpu.torch', \n",
    "                        map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    }
   ],
   "source": [
    "q2emb = Query2Emb(lang_model = lang_model.cpu(),\n",
    "                  vocab = vocab)\n",
    "\n",
    "search_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "\n",
    "# use pre build index \n",
    "#TODO: rebuild index for bigger data set\n",
    "search_index.loadIndex('./data/stackoverflow/lang_model_emb/dim500_avg_searchindex.nmslib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test = q2emb.emb_mean('Hello World!  This is a test.')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    \"\"\"Organizes all the necessary elements we need to make a search engine.\"\"\"\n",
    "    def __init__(self, \n",
    "                 nmslib_index, \n",
    "                 ref_df, \n",
    "                 query2emb_func):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ==========\n",
    "        nmslib_index : nmslib object\n",
    "            This is pre-computed search index.\n",
    "        ref_df : pandas.DataFrame\n",
    "            This dataframe contains meta-data for search results, \n",
    "            must contain the columns 'code' and 'url'.\n",
    "        query2emb_func : callable\n",
    "            This is a function that takes as input a string and returns a vector\n",
    "            that is in the same vector space as what is loaded into the search index.\n",
    "\n",
    "        \"\"\"\n",
    "        assert 'url' in ref_df.columns\n",
    "        assert 'content' in ref_df.columns\n",
    "        \n",
    "        self.search_index = nmslib_index\n",
    "        self.ref_df = ref_df\n",
    "        self.query2emb_func = query2emb_func\n",
    "    \n",
    "    def search(self, str_search, k=20):\n",
    "        \"\"\"\n",
    "        Prints the code that are the nearest neighbors (by cosine distance)\n",
    "        to the search query.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        str_search : str\n",
    "            a search query.  Ex: \"read data into pandas dataframe\"\n",
    "        k : int\n",
    "            the number of nearest neighbors to return.  Defaults to 2.\n",
    "        \n",
    "        \"\"\"\n",
    "        query = self.query2emb_func(str_search)\n",
    "        idxs, dists = self.search_index.knnQuery(query, k=k)\n",
    "        \n",
    "        for idx, dist in zip(idxs, dists):\n",
    "            content = self.ref_df.iloc[idx].content\n",
    "            url = self.ref_df.iloc[idx].url\n",
    "            print(f'cosine dist:{dist:.4f}  url: {url}\\n---------------\\n')\n",
    "            print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = search_engine(nmslib_index=search_index,\n",
    "                   ref_df=ref_df,\n",
    "                   query2emb_func=q2emb.emb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.0904  url: https://stackoverflow.com/a/20262821\n",
      "---------------\n",
      "\n",
      "read in your file :\n",
      "cosine dist:0.1003  url: https://stackoverflow.com/a/33471224\n",
      "---------------\n",
      "\n",
      "read the log :\n",
      "cosine dist:0.1052  url: https://stackoverflow.com/a/40093543\n",
      "---------------\n",
      "\n",
      "read in binary mode :\n",
      "cosine dist:0.1168  url: https://stackoverflow.com/a/7368575\n",
      "---------------\n",
      "\n",
      "read the help :\n",
      "cosine dist:0.1238  url: https://stackoverflow.com/a/14187749\n",
      "---------------\n",
      "\n",
      "read the documentation for :\n",
      "cosine dist:0.1314  url: https://stackoverflow.com/a/12149173\n",
      "---------------\n",
      "\n",
      "read this : http://www.michelepasin.org/techblog/2010/07/20/the-power-of-djangos-q-objects/\n",
      "cosine dist:0.1367  url: https://stackoverflow.com/a/15184426\n",
      "---------------\n",
      "\n",
      "read the documentation on the queue .\n",
      "cosine dist:0.1381  url: https://stackoverflow.com/a/28818016\n",
      "---------------\n",
      "\n",
      "read the csvs 's in using pd.read_csv(file )\n",
      "cosine dist:0.1431  url: https://stackoverflow.com/a/5913767\n",
      "---------------\n",
      "\n",
      "read about the qwidget.windowflags property : http://doc.qt.nokia.com/4.7/qwidget.html#windowflags-prop\n",
      "cosine dist:0.1451  url: https://stackoverflow.com/a/48089266\n",
      "---------------\n",
      "\n",
      "read your dataframe -\n",
      "cosine dist:0.1457  url: https://stackoverflow.com/a/14542772\n",
      "---------------\n",
      "\n",
      "reading the notes from sys.setrecursionlimit\n",
      "cosine dist:0.1551  url: https://stackoverflow.com/a/34446845\n",
      "---------------\n",
      "\n",
      "read unique_together from django docs\n",
      "cosine dist:0.1558  url: https://stackoverflow.com/a/35772167\n",
      "---------------\n",
      "\n",
      "read the documentation : manage data in containers\n",
      "cosine dist:0.1579  url: https://stackoverflow.com/a/8711061\n",
      "---------------\n",
      "\n",
      "read the binary file content like this :\n",
      "cosine dist:0.1687  url: https://stackoverflow.com/a/5338647\n",
      "---------------\n",
      "\n",
      "read a generic example here : http://programming-guides.com/python/timeout-a-function\n",
      "cosine dist:0.1695  url: https://stackoverflow.com/a/2580707\n",
      "---------------\n",
      "\n",
      "read your original regex carefully :\n",
      "cosine dist:0.1735  url: https://stackoverflow.com/a/10683671\n",
      "---------------\n",
      "\n",
      "read your error messages :\n",
      "cosine dist:0.1763  url: https://stackoverflow.com/a/7472788\n",
      "---------------\n",
      "\n",
      "read this , and follow the instructions : http://code.google.com/p/pypcap/issues/detail?id=27#c6\n",
      "cosine dist:0.1788  url: https://stackoverflow.com/a/34413753\n",
      "---------------\n",
      "\n",
      "you can read from multiple sheets with pandas :\n",
      "cosine dist:0.1825  url: https://stackoverflow.com/a/45346803\n",
      "---------------\n",
      "\n",
      "first read your csv file with pandas with\n"
     ]
    }
   ],
   "source": [
    "se.search(\"read from csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return top 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
